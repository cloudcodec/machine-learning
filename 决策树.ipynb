{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <center>决策树(ID3)</center>\n",
    "\n",
    "## 模型\n",
    "假设当前节点数据集D1，两个特征A1,A2,信息增益\n",
    "$$g(D1,A1)=H(D1)-H(D1|A1)$$\n",
    "$$g(D1,A2)=H(D1)-H(D1|A2)$$\n",
    "如果g(D1,A1)>g(D1,A2)则选特征A1，否则选特征A2\n",
    "\n",
    "说明:g(D1,A1)>g(D1,A2),则H(D1|A1)<H(D1|A2),熵越小=不确定性越小=越确定，所以决策树越往底层越能确定分类\n",
    "\n",
    "## 公式\n",
    "$$H(D)=-\\sum_{k=1}^{K} \\frac{|C_{k}|}{|D|} \\log _{2} \\frac{|C_{k}|}{|D|}$$\n",
    "\n",
    "$$H(D | A)=\\sum_{i=1}^{n} \\frac{|D_{i}|}{|D|} H(D_{i})$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:1.0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,leaf,feature_index=None,label=None):\n",
    "        self.leaf=leaf\n",
    "        self.feature_index=feature_index\n",
    "        self.label=label\n",
    "        self.children={}\n",
    "\n",
    "    def add_child(self,feature_value,node):\n",
    "        self.children[feature_value]=node\n",
    "\n",
    "    def predict(self,x):\n",
    "        if self.leaf:\n",
    "            return self.label\n",
    "        return self.children[x[self.feature_index]].predict(x)\n",
    "\n",
    "# ID3\n",
    "class DecisionTree:\n",
    "    def __init__(self,epsilon=0.1):\n",
    "        self.epsilon=epsilon\n",
    "        self._tree=None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        # 合在一起便于一起拆分\n",
    "        data=np.hstack((X,y.reshape((-1,1))))\n",
    "        self._tree=self._build_tree(data,np.arange(X.shape[1]))\n",
    "\n",
    "    def predict(self,x):\n",
    "        return self._tree.predict(x)\n",
    "\n",
    "    # 只用于验证模型的正确性\n",
    "    def score(self, X,y):\n",
    "        count=0\n",
    "        for x,yi in zip(X, y):\n",
    "            if self.predict(x)==yi:\n",
    "                count+=1\n",
    "        return count/float(len(X))\n",
    "\n",
    "    def _build_tree(self,data,features_index):\n",
    "        y = data[:, -1]\n",
    "        unique_labels=np.unique(y)\n",
    "\n",
    "        if len(unique_labels)==1:\n",
    "            return Node(leaf=True,label=unique_labels[0])\n",
    "\n",
    "        if len(features_index)==0:\n",
    "            return Node(leaf=True,label=self._most(y))\n",
    "\n",
    "        max_info_gain_feature_index,max_info_gain=self._max_info_gain(data, features_index)\n",
    "        if max_info_gain<self.epsilon:\n",
    "            return Node(leaf=True,label=self._most(y))\n",
    "\n",
    "        node=Node(leaf=False,feature_index=max_info_gain_feature_index)\n",
    "        features_index_sub=np.delete(features_index,max_info_gain_feature_index)\n",
    "        for feature_value,data_sub in self._groupBy(data, max_info_gain_feature_index):\n",
    "            node.add_child(feature_value,self._build_tree(data_sub,features_index_sub))\n",
    "        return node\n",
    "\n",
    "    def _most(self, y):\n",
    "        counter=Counter(y)\n",
    "        return counter.most_common(1)[0]\n",
    "\n",
    "    def _max_info_gain(self, data, features_index):\n",
    "        y=data[:,-1]\n",
    "        H_D=self._entropy(y)\n",
    "        options=[]\n",
    "        for feature_index in features_index:\n",
    "            H_DA=self._cond_entropy(data,feature_index)\n",
    "            options.append((feature_index,H_D-H_DA))\n",
    "        return max(options,key=lambda x:x[1])\n",
    "\n",
    "    # return [(\"a\",[[\"a\",\"b\",\"y\"])]\n",
    "    def _groupBy(self, data, column):\n",
    "        res=[]\n",
    "        data=data[data[:, column].argsort()]\n",
    "        value_pre=None\n",
    "        data_sub=None\n",
    "        for i in range(len(data)+1):\n",
    "            if  i ==len(data) or (i != 0 and data[i, column] != value_pre):\n",
    "                res.append((value_pre,data_sub))\n",
    "                data_sub=None\n",
    "            if i!=len(data):\n",
    "                row=data[i,:]\n",
    "                if data_sub is None:\n",
    "                    data_sub=row.reshape(1,-1)\n",
    "                else:\n",
    "                    data_sub=np.vstack((data_sub,row))\n",
    "                value_pre=row[column]\n",
    "        return res\n",
    "\n",
    "    # H(D)\n",
    "    def _entropy(self,y):\n",
    "        length = len(y)\n",
    "        label_count = {}\n",
    "        for i in range(length):\n",
    "            label = y[i]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "        return -np.sum([(v / float(length) * np.log2(v / length)) for v in label_count.values()])\n",
    "\n",
    "\n",
    "    # H(D|A)\n",
    "    def _cond_entropy(self,data,feature_index):\n",
    "        return sum([(len(Di)/float(len(data)))*self._entropy(Di[:,-1]) for _,Di in self._groupBy(data,feature_index)])\n",
    "\n",
    "\n",
    "def create_data():\n",
    "     datasets =np.array([['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ])\n",
    "     return datasets[:,:-1],datasets[:,-1]\n",
    "\n",
    "X,y=create_data()\n",
    "\n",
    "model=DecisionTree()\n",
    "model.fit(X,y)\n",
    "print(f\"score:{model.score(X,y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}